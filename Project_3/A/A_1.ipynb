{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Δημιουργία dataframe διαβάζοντας τo csv που δόθηκε.\n",
    "# Τοποθετήστε το δικό σας path \n",
    "\n",
    "df = pd.read_csv(\"nasdaq2007_17.csv\", '\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()\n",
    "new_header = df.iloc[0] \n",
    "df = df[1:] \n",
    "df.columns = new_header\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = sample(range(0, len(df.columns)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [11, 260, 317, 134, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in list:\n",
    "    train_size = int(len(df) * 0.80)\n",
    "    test_size = len(df) - train_size  \n",
    "\n",
    "    training_set = df.iloc[:train_size,j:j+1].values\n",
    "    test_set = df.iloc[train_size:,j:j+1].values\n",
    "\n",
    "    Time_step = 60\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "    # Creating a data structure with 60 time-steps and 1 output\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(Time_step, train_size):\n",
    "        X_train.append(training_set_scaled[i-Time_step:i, 0])\n",
    "        y_train.append(training_set_scaled[i, 0])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "    model = Sequential()\n",
    "    layer = 50\n",
    "    #Adding the first LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = layer, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Adding a second LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = layer, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Adding a third LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = layer, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Adding a fourth LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = layer))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    # Fitting the RNN to the Training set\n",
    "    model.fit(X_train, y_train, epochs = 5, batch_size = 512)\n",
    "\n",
    "#####################################################################################\n",
    "    path ='myModel'+str(j)\n",
    "    model.save(path)\n",
    "#####################################################################################\n",
    "\n",
    "    dataset_train = df.iloc[:train_size,j:j+1]\n",
    "    dataset_test = df.iloc[train_size:, j:j+1]\n",
    "    dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)\n",
    "    inputs = dataset_total[len(dataset_total) - len(dataset_test) - Time_step:].values\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    inputs = sc.transform(inputs)\n",
    "    X_test = []\n",
    "    for i in range(Time_step, test_size + Time_step):\n",
    "        X_test.append(inputs[i-Time_step:i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    print(X_test.shape)\n",
    "\n",
    "    predicted_stock_price = model.predict(X_test)\n",
    "    predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "    print(j)\n",
    "    plt.plot(dataset_test.values, color = 'red', label = 'Real')\n",
    "    plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted')\n",
    "    plt.xticks(np.arange(0,test_size,Time_step))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c65b98e956c6ae24f8ae0bc56d1e465ff92310dbdec0a4bd6b48ffdf1441c98"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "4c65b98e956c6ae24f8ae0bc56d1e465ff92310dbdec0a4bd6b48ffdf1441c98"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
